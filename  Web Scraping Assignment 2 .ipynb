{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7af90a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (4.8.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af3ef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8165d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d4231",
   "metadata": {},
   "source": [
    "# Question 1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e61b6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bef31785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required  in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a440af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location as required in question\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "288e1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for search button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c32fffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21df0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping experience required from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de28d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d83f5da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ingersoll Rand</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - EdTech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talentstack</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Unusual Hire</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Contractual</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Search Advisers Services Guj</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Contractual</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Search Advisers Services Guj</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - MySQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talentstack</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExcelHER-Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Volvo Financial Services</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...</td>\n",
       "      <td>Allegis Group</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Clarivate</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Job_title  \\\n",
       "0                Data Analyst   \n",
       "1       Data Analyst - EdTech   \n",
       "2                Data Analyst   \n",
       "3  Data Analyst - Contractual   \n",
       "4  Data Analyst - Contractual   \n",
       "5        Data Analyst - MySQL   \n",
       "6       ExcelHER-Data Analyst   \n",
       "7                Data Analyst   \n",
       "8                Data Analyst   \n",
       "9                Data Analyst   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "7  Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                   Company_name Exp_required  \n",
       "0                Ingersoll Rand      3-6 Yrs  \n",
       "1                   Talentstack      2-6 Yrs  \n",
       "2                  Unusual Hire      1-4 Yrs  \n",
       "3  Search Advisers Services Guj      2-3 Yrs  \n",
       "4  Search Advisers Services Guj      2-3 Yrs  \n",
       "5                   Talentstack      2-7 Yrs  \n",
       "6      Volvo Financial Services      3-5 Yrs  \n",
       "7                 Allegis Group      4-9 Yrs  \n",
       "8                     Clarivate      2-4 Yrs  \n",
       "9                  Novel Office      0-2 Yrs  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd4360",
   "metadata": {},
   "source": [
    "# Question 2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "564f6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8f18028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09cdf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location as required in question\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8eb59200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for search button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94274b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4930bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping exprience from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft br2 placeHolderLi experience\"]/span[1]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89c0a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b06e6412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Professional - IBM SPSS Statistic...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai, Pune, Chennai</td>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior data scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager - Innovations Hub - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>7-11 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Data Science Professional - IBM SPSS Statistic...   \n",
       "1                            Data Science Specialist   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3                              Senior data scientist   \n",
       "4                                 Data Scientist_NLP   \n",
       "5                                     Data Scientist   \n",
       "6                    Machine Learning (AI) Architect   \n",
       "7       Manager - Innovations Hub - Machine Learning   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_location           Company_name  \\\n",
       "0  Bangalore/Bengaluru, Noida, Mumbai, Pune, Chennai  Hexaware Technologies   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...              Accenture   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...              Accenture   \n",
       "3  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...      Fractal Analytics   \n",
       "4  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...      Fractal Analytics   \n",
       "5  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...      Fractal Analytics   \n",
       "6  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...             Persistent   \n",
       "7  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...                    PwC   \n",
       "8                                Bangalore/Bengaluru                    IBM   \n",
       "9                                Bangalore/Bengaluru                    IBM   \n",
       "\n",
       "  Exp_required  \n",
       "0      5-8 Yrs  \n",
       "1      2-4 Yrs  \n",
       "2      6-8 Yrs  \n",
       "3      4-8 Yrs  \n",
       "4     5-11 Yrs  \n",
       "5      3-7 Yrs  \n",
       "6     5-12 Yrs  \n",
       "7      7-9 Yrs  \n",
       "8      7-9 Yrs  \n",
       "9     7-11 Yrs  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456ea5a",
   "metadata": {},
   "source": [
    "# Question 3: In this question you have to scrape data using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb143c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee5081e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61b4bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5c61d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for search button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f7da850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling location filter checkbox by using XPATH\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[1]/div[2]/div[2]/label/p/span[1]\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17f53bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling Salary filter checkbox by using XPATH\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[2]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7efa76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe717f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping exprience from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft br2 placeHolderLi experience\"]/span[1]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3778e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "80ae6900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capgemini _We Are Hiring For Java Backend deve...</td>\n",
       "      <td>Hybrid - Kolkata, Hyderabad/Secunderabad, Pune...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenText Extended ECM/xECM</td>\n",
       "      <td>Hybrid - Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java Back End Developer</td>\n",
       "      <td>Hybrid - Hyderabad/Secunderabad, Pune, Bangalo...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Microservice Developer</td>\n",
       "      <td>Hybrid - Noida, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>Publicis Resources</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORMB Developer</td>\n",
       "      <td>Hybrid - Noida, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>People Staffing</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Java Developer</td>\n",
       "      <td>Hybrid - Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring --Java developer</td>\n",
       "      <td>Hybrid - Mumbai, Hyderabad/Secunderabad, Banga...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Php Developer</td>\n",
       "      <td>Hybrid - Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Publicis</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Lead Developer</td>\n",
       "      <td>Hybrid - Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dotnet Core Developers</td>\n",
       "      <td>Hybrid - Hyderabad/Secunderabad(Kondapur), Ban...</td>\n",
       "      <td>3i Infotech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Capgemini _We Are Hiring For Java Backend deve...   \n",
       "1                         OpenText Extended ECM/xECM   \n",
       "2                            Java Back End Developer   \n",
       "3                        Java Microservice Developer   \n",
       "4                                     ORMB Developer   \n",
       "5                              Senior Java Developer   \n",
       "6                            Hiring --Java developer   \n",
       "7                                      Php Developer   \n",
       "8                              Python Lead Developer   \n",
       "9                             Dotnet Core Developers   \n",
       "\n",
       "                                        Job_location        Company_name  \\\n",
       "0  Hybrid - Kolkata, Hyderabad/Secunderabad, Pune...           Capgemini   \n",
       "1  Hybrid - Hyderabad/Secunderabad, Pune, Chennai...               Wipro   \n",
       "2  Hybrid - Hyderabad/Secunderabad, Pune, Bangalo...       Tech Mahindra   \n",
       "3  Hybrid - Noida, Hyderabad/Secunderabad, Pune, ...  Publicis Resources   \n",
       "4  Hybrid - Noida, Hyderabad/Secunderabad, Pune, ...     People Staffing   \n",
       "5    Hybrid - Pune, Bangalore/Bengaluru, Delhi / NCR             Genpact   \n",
       "6  Hybrid - Mumbai, Hyderabad/Secunderabad, Banga...       Tech Mahindra   \n",
       "7  Hybrid - Gurgaon/Gurugram, Bangalore/Bengaluru...            Publicis   \n",
       "8     Hybrid - Gurgaon/Gurugram, Bangalore/Bengaluru               Wipro   \n",
       "9  Hybrid - Hyderabad/Secunderabad(Kondapur), Ban...         3i Infotech   \n",
       "\n",
       "  Exp_required  \n",
       "0     6-11 Yrs  \n",
       "1     5-10 Yrs  \n",
       "2      5-9 Yrs  \n",
       "3     7-12 Yrs  \n",
       "4      3-7 Yrs  \n",
       "5     5-10 Yrs  \n",
       "6      4-9 Yrs  \n",
       "7      0-2 Yrs  \n",
       "8      6-9 Yrs  \n",
       "9      5-9 Yrs  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67962a58",
   "metadata": {},
   "source": [
    "# Question 4: Scrape data of first 100 sunglasses listings on flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2d027030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (4.8.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b43267e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a6b6696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e4483db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a04d174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question\n",
    "search_bar=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search_bar.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "541bab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for search button\n",
    "search_icon=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ec775a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "branded_sunglasses=[]\n",
    "product_description=[]\n",
    "sunglasses_price=[]\n",
    "discounted_sunglasses=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "01a6afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    # scraping data of 100 branded sunglasses from flipkart web page\n",
    "    sunglasses_brand=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in sunglasses_brand:\n",
    "        branded_sunglasses.append(brand.text)\n",
    "    \n",
    "    # scraping data with 100 product description of sunglasses from flipkart web page\n",
    "    descriptive_product=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for description in descriptive_product:\n",
    "        product_description.append(description.text)\n",
    "    \n",
    "    # scraping data with price of 100 sunglasses from flipkart web page\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for prs in price_tag:\n",
    "        sunglasses_price.append(prs.text)\n",
    "    \n",
    "    # scraping data with price of 100 sunglasses from flipkart web page\n",
    "    sunglasses_discount=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for offer in sunglasses_discount:\n",
    "        discounted_sunglasses.append(offer.text)\n",
    "        \n",
    "    #using XPATH for change the page\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ad17dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 156 120 120\n"
     ]
    }
   ],
   "source": [
    "#checking length\n",
    "print(len(branded_sunglasses),len(product_description),len(sunglasses_price),len(discounted_sunglasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9c79290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- First 100 sunglasses -----------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹919</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹854</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹149</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹569</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RBILZ</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, Night Vision, Polarized, Photochroma...</td>\n",
       "      <td>₹99</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹169</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection Spectacle Sunglasses (Free Size)</td>\n",
       "      <td>₹569</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ARICKS</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹899</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product Description Price  \\\n",
       "0   VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹919   \n",
       "1   VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹854   \n",
       "2            SRPM             UV Protection Wayfarer Sunglasses (50)  ₹149   \n",
       "3        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹569   \n",
       "4       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  ₹149   \n",
       "..            ...                                                ...   ...   \n",
       "95          RBILZ   UV Protection Rectangular Sunglasses (Free Size)  ₹249   \n",
       "96       Fastrack  Gradient, Night Vision, Polarized, Photochroma...   ₹99   \n",
       "97       Fastrack  by Lenskart Polarized, UV Protection Cat-eye S...  ₹169   \n",
       "98         SUNBEE     UV Protection Spectacle Sunglasses (Free Size)  ₹569   \n",
       "99         ARICKS  Polarized, UV Protection, Riding Glasses Wayfa...  ₹899   \n",
       "\n",
       "   Discount  \n",
       "0   54% off  \n",
       "1   57% off  \n",
       "2   88% off  \n",
       "3   48% off  \n",
       "4   75% off  \n",
       "..      ...  \n",
       "95  75% off  \n",
       "96  88% off  \n",
       "97  86% off  \n",
       "98  48% off  \n",
       "99  65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Brand':branded_sunglasses[0:100],'Product Description':product_description[0:100],'Price':sunglasses_price[0:100],'Discount':discounted_sunglasses[0:100]})\n",
    "print('-'*22,\"First 100 sunglasses\",'-'*23)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf1e96",
   "metadata": {},
   "source": [
    "# Question5: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d7f7ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6049a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the iphone11 Ratings & Reviews page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b145deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5fb5fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The page contain only 10 reviews, need to click on '+' to get all 100 reviews\n",
    "start=0\n",
    "end=20\n",
    "for page in range(start,end):\n",
    "    # scraping data of ratings of iphone11 from flipkart web page\n",
    "    ratings_ipone11=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for rating in ratings_ipone11:\n",
    "        iphone_rating.append(rating.text)\n",
    "    \n",
    "    # scraping data with reviw of iphone11 from flipkart web page\n",
    "    review_iphone11=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for review in review_iphone11:\n",
    "        review_summary.append(review.text)\n",
    "    \n",
    "    # scraping data with all 100 reviw of iphone11 from flipkart web page\n",
    "    entire_review=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for reviews in entire_review:\n",
    "        full_review.append(reviews.text)\n",
    "        \n",
    "    #using XPATH for change the page\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fbbedf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "#checking length\n",
    "print(len(iphone_rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f61a1dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3                                \n",
       "4                                \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5     Perfect product!   \n",
       "97      4          Pretty good   \n",
       "98      5   Highly recommended   \n",
       "99      5        Great product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3                                                      \n",
       "4                                                      \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Value for money\\n5 star rating\\nExcellent came...  \n",
       "97  I was using Iphone 6s and also Oneplus 6t. Bot...  \n",
       "98  What a camera .....just awesome ..you can feel...  \n",
       "99  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Rating':iphone_rating[0:100],'Review Summary':review_summary[0:100],'Full Review':full_review[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a28a3",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c4864fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d0b9afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "220778ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sneakers as required in the question\n",
    "search_bar=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search_bar.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "da7e9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for search button\n",
    "search_icon=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/buttonsneakers')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "06158cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "branded_sneakers=[]\n",
    "sneakers_description=[]\n",
    "sneakers_price=[]\n",
    "discounted_sneakers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "dd8d570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    # scraping data of 100 branded sneakers from flipkart web page\n",
    "    sneakers_brand=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in sneakers_brand:\n",
    "        branded_sneakers.append(brand.text)\n",
    "    \n",
    "    # scraping data with 100 product description of sneakers from flipkart web page\n",
    "    descriptive_product=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for descriptive in descriptive_product:\n",
    "        sneakers_description.append(descriptive.text)\n",
    "    \n",
    "    # scraping data with price of 100 sneakers from flipkart web page\n",
    "    worth_sneakers=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for worth in worth_sneakers:\n",
    "        sneakers_price.append(worth.text)\n",
    "    \n",
    "    # scraping data with price of 100 sneakers from flipkart web page\n",
    "    sneakers_discounted=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for deduction in sneakers_discounted:\n",
    "        discounted_sneakers.append(deduction.text)\n",
    "        \n",
    "    #using XPATH for change the page\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9595718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 117 120 119\n"
     ]
    }
   ],
   "source": [
    "#checking length\n",
    "print(len(branded_sneakers),len(sneakers_description),len(sneakers_price),len(discounted_sneakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "799690d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>373 Sneakers For Men</td>\n",
       "      <td>₹5,244</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>327 Sneakers For Men</td>\n",
       "      <td>₹4,199</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Latest Exclusive Affordable Collection of Tren...</td>\n",
       "      <td>₹279</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹279</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers Sneakers ...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zixer</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹666</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Roadster Wonen's White Faux Leather Casual Lac...</td>\n",
       "      <td>₹1,109</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                Product Description  \\\n",
       "0           New Balance                               373 Sneakers For Men   \n",
       "1           New Balance                               327 Sneakers For Men   \n",
       "2   World Wear Footwear  Latest Exclusive Affordable Collection of Tren...   \n",
       "3                   SFR                                   Sneakers For Men   \n",
       "4                Kraasa                                 Sneakers For Women   \n",
       "..                  ...                                                ...   \n",
       "95        WHITE WALKERS  Modern Trendy Sneakers boot Sneakers Sneakers ...   \n",
       "96                Zixer      Combo Pack Of 2 Casual Shoes Sneakers For Men   \n",
       "97             Roadster  Roadster Wonen's White Faux Leather Casual Lac...   \n",
       "98             Magnolia                                   Sneakers For Men   \n",
       "99                BIRDE               Modern Trendy Shoes Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0   ₹5,244  52% off  \n",
       "1   ₹4,199  58% off  \n",
       "2     ₹279  86% off  \n",
       "3     ₹279  67% off  \n",
       "4     ₹299  70% off  \n",
       "..     ...      ...  \n",
       "95    ₹449  70% off  \n",
       "96    ₹666  66% off  \n",
       "97  ₹1,109  63% off  \n",
       "98    ₹399  69% off  \n",
       "99    ₹499  50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Brand':branded_sneakers[0:100],'Product Description':sneakers_description[0:100],'Price':sneakers_price[0:100],'Discount':discounted_sneakers[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500894b",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7301c464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (4.8.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3426457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e015123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1d6d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "463728e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question\n",
    "search_bar=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_bar.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "417403b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for search button\n",
    "search_icon=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37ec1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for setting  filter type “Intel Core i7” \n",
    "filter_type=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/li[9]/span/a/div/label/i')\n",
    "filter_type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54df71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_title=[]\n",
    "Laptop_rating=[]\n",
    "Laptop_price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aeea987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    # scraping data of 100 branded sneakers from flipkart web page\n",
    "    Laptopi7_title=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for title in Laptopi7_title:\n",
    "        Laptop_title.append(title.text)\n",
    "    \n",
    "    # scraping data with 100 product description of sneakers from flipkart web page\n",
    "    Laptopi7_rating=driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "    for rating in Laptopi7_rating:\n",
    "        Laptop_rating.append(rating.text)\n",
    "    \n",
    "    # scraping data with price of 100 sneakers from flipkart web page\n",
    "    Laptopi7_price=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "    for price in Laptopi7_price:\n",
    "        Laptop_price.append(price.text)\n",
    "        \n",
    "    #using XPATH for change the page\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8287e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 67 136\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(Laptop_title),len(Laptop_rating),len(Laptop_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc99ca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 (NP750) Intel 12th Gen co...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Dash F15, Intel Core i7-12650H 12th G...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop 7390 Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell G15-5520 Gaming Laptop, i7-12650H, 16GB D...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings Price\n",
       "0  HP Victus Gaming Latest 12th Gen Intel Core i7...              \n",
       "1  Samsung Galaxy Book2 (NP750) Intel 12th Gen co...              \n",
       "2  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...              \n",
       "3  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...              \n",
       "4  ASUS TUF Dash F15, Intel Core i7-12650H 12th G...              \n",
       "5  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...              \n",
       "6  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...              \n",
       "7  (Renewed) Dell Latitude Laptop 7390 Intel Core...              \n",
       "8  Dell G15-5520 Gaming Laptop, i7-12650H, 16GB D...              \n",
       "9  ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...              "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Title':Laptop_title[0:10],'Ratings':Laptop_rating[0:10],'Price':Laptop_price[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec61c1",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bd3e76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "42fa2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b596866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for clicking GK OPTION\n",
    "Top_Quotes=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "Top_Quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fac1b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all click on quotes left middle side\n",
    "Quote=[]\n",
    "Author=[]\n",
    "Type_Of_Quotes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "58378661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    # scraping data of 1000 quotes from  azquotes page\n",
    "    quote_tag=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for quotes in quote_tag:\n",
    "        Quote.append(quotes.text)\n",
    "    \n",
    "    # scraping data of Author's from azquotes page\n",
    "    author_tag=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for authors in author_tag:\n",
    "        Author.append(authors.text)\n",
    "    \n",
    "    # scraping data of Type_Of_Quotes from azquotes page\n",
    "    quotes_tag=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for thought in quotes_tag:\n",
    "        Type_Of_Quotes.append(thought.text)\n",
    "\n",
    "    #using XPATH for change the page\n",
    "    next_button=driver.find_element(By.XPATH,'//div[@class=\"pager\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a5820ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 2100 2100\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(Quote),len(Author),len(Type_Of_Quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "763c42f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type_Of_Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The average dog is a nicer person than the ave...</td>\n",
       "      <td>Andy Rooney</td>\n",
       "      <td>Inspirational, Funny, Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America will never be destroyed from the outsi...</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Wisdom, Religious, Freedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Faithful servants never retire. You can retire...</td>\n",
       "      <td>Rick Warren</td>\n",
       "      <td>Reality, Servant Of God, Careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>In matters of style, swim with the current; in...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>Inspirational, Motivational, Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Dad needs to show an incredible amount of resp...</td>\n",
       "      <td>Tim Allen</td>\n",
       "      <td>Friendship, Teamwork, Mom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  The average dog is a nicer person than the ave...         Andy Rooney   \n",
       "996  America will never be destroyed from the outsi...     Abraham Lincoln   \n",
       "997  Faithful servants never retire. You can retire...         Rick Warren   \n",
       "998  In matters of style, swim with the current; in...    Thomas Jefferson   \n",
       "999  Dad needs to show an incredible amount of resp...           Tim Allen   \n",
       "\n",
       "                               Type_Of_Quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995                 Inspirational, Funny, Dog  \n",
       "996                Wisdom, Religious, Freedom  \n",
       "997          Reality, Servant Of God, Careers  \n",
       "998      Inspirational, Motivational, Success  \n",
       "999                 Friendship, Teamwork, Mom  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Quote':Quote[0:1000],'Author':Author[0:1000],'Type_Of_Quotes':Type_Of_Quotes[0:1000]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea30fb",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,Term of office, Remarks) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8836bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (4.8.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64a393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4f988480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "92e5cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "505a5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for clicking GK OPTION\n",
    "gk_option=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[1]/div/div[3]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "gk_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "af9e2704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for clicking GK OPTION\n",
    "PM_list=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "PM_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b133079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_minister_Name=[]\n",
    "prime_minister_Born_Dead=[]\n",
    "prime_minister_Term_of_office=[]\n",
    "_prime_minister_Remarks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fe70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data for getting list of former Prime Ministers of India from jagranjosh page\n",
    "name_tag=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "for name in name_tag:\n",
    "    prime_minister_Name.append(name.text)\n",
    "    \n",
    "# scraping data for getting date of birth and death of former Prime Ministers of India from jagranjosh page\n",
    "bd_tag=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[4]/p')\n",
    "for bd in bd_tag:\n",
    "    prime_minister_Born_Dead.append(bd.text)\n",
    "    \n",
    "# scraping data for getting service period of former Prime Ministers of India from jagranjosh page\n",
    "period_tag=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for period in period_tag:\n",
    "    prime_minister_Term_of_office.append(period.text)\n",
    "    \n",
    "# scraping data for getting remaks of former Prime Ministers of India from jagranjosh page\n",
    "remarks_tag=driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for remark in remarks_tag:\n",
    "    _prime_minister_Remarks.append(remark.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "170cff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2 2 2\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(Name),len(Born_Dead),len(Term_of_office),len(Remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Name':Name,'Born_Dead':Born_Dead,'Term_of_office':Term_of_office,'Remarks':Remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c94898",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "466745b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sachin Sharma\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9e954cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the motor1 page on automated chrome browser\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "61639c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for Menu OPTION\n",
    "list_menu=driver.find_element(By.XPATH,'/html/body/div[3]/div[2]/div/div/div[1]/div')\n",
    "list_menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "68fff348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for clicking FEATURES in list\n",
    "features_menu=driver.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[5]/a')\n",
    "features_menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "97b4fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XPATH for clicking 50 Most Expensive Cars In The World \n",
    "expensive_car=driver.find_element(By.XPATH,'/html/body/div[3]/div[6]/div/div[1]/div[1]/div[3]/div/div[1]/h3/a')\n",
    "expensive_car.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "12de178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name=[]\n",
    "car_price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b5771369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scraping data for getting Name of 50 Most Expensive Cars In The World from motor1 page\n",
    "luxury_name=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for car in luxury_name:\n",
    "    car_name.append(car.text)\n",
    "    \n",
    "# scraping data for getting Price of 50 Most Expensive Cars In The World from motor1 page\n",
    "luxury_price=driver.find_elements(By.XPATH,'//strong')\n",
    "for price in luxury_price:\n",
    "    car_price.append(price.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bb339f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 171\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(car_name),len(car_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b73723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe from above data-\n",
    "df=pd.DataFrame({'50 Most Expensive Cars In The World':car_name,'Price':car_price})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
