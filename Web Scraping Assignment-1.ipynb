{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95ac7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: html5lib in c:\\users\\sachin sharma\\appdata\\roaming\\python\\python39\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e93ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e21af01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Main Page',\n",
       " 'h1 Welcome to Wikipedia',\n",
       " \"h2 From today's featured article\",\n",
       " 'h2 Did you know\\xa0...',\n",
       " 'h2 In the news',\n",
       " 'h2 On this day',\n",
       " \"h2 Today's featured picture\",\n",
       " 'h2 Other areas of Wikipedia',\n",
       " \"h2 Wikipedia's sister projects\",\n",
       " 'h2 Wikipedia languages']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.write a python program to display all the header tags from 'en.wikipedia.org/wiki/main_page'.\n",
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "header_tags = [] # empty list\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "    \n",
    "# print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5af547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.235649184615554</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.155945794180111</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.99110705872849</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>8.98391121563782</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.952673659954899</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.939690003551755</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.931665765609097</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.846886757850855</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>8.810555692635617</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.789498179053293</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8.766858342269497</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.748061807923964</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>8.736125377987946</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.732751025994641</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>8.698703887140217</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>8.669241979625076</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>8.652905521805813</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>8.638288851089232</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>8.604497240222022</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.59808432198398</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.59744906524363</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>8.588247062567454</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.579513442391537</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>8.579502826468591</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.570395186367547</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.568488399951171</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.563199081775402</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>8.54831736910251</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.537837704858486</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.51778983109081</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>8.516001025151718</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.507440022104177</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>8.506525235661378</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>8.499733529289214</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.4935964820457</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>8.487957875520902</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.487001051769603</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>American History X</td>\n",
       "      <td>8.481795436224361</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>8.476128780755719</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>8.469770366673465</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>8.469242024239946</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>8.468289672391537</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>8.461660993904445</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>8.455942951890448</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>8.455915628285805</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.453762148870833</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>8.447105852582967</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>8.441058124743886</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>8.43564247159922</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>8.435058180961015</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name             Rating  \\\n",
       "0                            The Shawshank Redemption  9.235649184615554   \n",
       "1                                       The Godfather  9.155945794180111   \n",
       "2                                     The Dark Knight   8.99110705872849   \n",
       "3                               The Godfather Part II   8.98391121563782   \n",
       "4                                        12 Angry Men  8.952673659954899   \n",
       "5                                    Schindler's List  8.939690003551755   \n",
       "6       The Lord of the Rings: The Return of the King  8.931665765609097   \n",
       "7                                        Pulp Fiction  8.846886757850855   \n",
       "8   The Lord of the Rings: The Fellowship of the Ring  8.810555692635617   \n",
       "9                     Il buono, il brutto, il cattivo  8.789498179053293   \n",
       "10                                       Forrest Gump  8.766858342269497   \n",
       "11                                         Fight Club  8.748061807923964   \n",
       "12              The Lord of the Rings: The Two Towers  8.736125377987946   \n",
       "13                                          Inception  8.732751025994641   \n",
       "14                            The Empire Strikes Back  8.698703887140217   \n",
       "15                                         The Matrix  8.669241979625076   \n",
       "16                                         GoodFellas  8.652905521805813   \n",
       "17                    One Flew Over the Cuckoo's Nest  8.638288851089232   \n",
       "18                                              Se7en  8.604497240222022   \n",
       "19                               Shichinin no samurai   8.59808432198398   \n",
       "20                              It's a Wonderful Life   8.59744906524363   \n",
       "21                           The Silence of the Lambs  8.588247062567454   \n",
       "22                                Saving Private Ryan  8.579513442391537   \n",
       "23                                     Cidade de Deus  8.579502826468591   \n",
       "24                                       Interstellar  8.570395186367547   \n",
       "25                                    La vita è bella  8.568488399951171   \n",
       "26                                     The Green Mile  8.563199081775402   \n",
       "27                                          Star Wars   8.54831736910251   \n",
       "28                         Terminator 2: Judgment Day  8.537837704858486   \n",
       "29                                 Back to the Future   8.51778983109081   \n",
       "30                      Sen to Chihiro no kamikakushi  8.516001025151718   \n",
       "31                                        The Pianist  8.507440022104177   \n",
       "32                                             Psycho  8.506525235661378   \n",
       "33                                       Gisaengchung  8.499733529289214   \n",
       "34                                               Léon    8.4935964820457   \n",
       "35                                      The Lion King  8.487957875520902   \n",
       "36                                          Gladiator  8.487001051769603   \n",
       "37                                 American History X  8.481795436224361   \n",
       "38                                       The Departed  8.476128780755719   \n",
       "39                                 The Usual Suspects  8.469770366673465   \n",
       "40                                       The Prestige  8.469242024239946   \n",
       "41                                           Whiplash  8.468289672391537   \n",
       "42                                         Casablanca  8.461660993904445   \n",
       "43                                     Hotaru no haka  8.455942951890448   \n",
       "44                                            Seppuku  8.455915628285805   \n",
       "45                                   The Intouchables  8.453762148870833   \n",
       "46                                       Modern Times  8.447105852582967   \n",
       "47                       Once Upon a Time in the West  8.441058124743886   \n",
       "48                                        Rear Window   8.43564247159922   \n",
       "49                              Nuovo Cinema Paradiso  8.435058180961015   \n",
       "\n",
       "   Year of Release  \n",
       "0             1994  \n",
       "1             1972  \n",
       "2             2008  \n",
       "3             1974  \n",
       "4             1957  \n",
       "5             1993  \n",
       "6             2003  \n",
       "7             1994  \n",
       "8             2001  \n",
       "9             1966  \n",
       "10            1994  \n",
       "11            1999  \n",
       "12            2002  \n",
       "13            2010  \n",
       "14            1980  \n",
       "15            1999  \n",
       "16            1990  \n",
       "17            1975  \n",
       "18            1995  \n",
       "19            1954  \n",
       "20            1946  \n",
       "21            1991  \n",
       "22            1998  \n",
       "23            2002  \n",
       "24            2014  \n",
       "25            1997  \n",
       "26            1999  \n",
       "27            1977  \n",
       "28            1991  \n",
       "29            1985  \n",
       "30            2001  \n",
       "31            2002  \n",
       "32            1960  \n",
       "33            2019  \n",
       "34            1994  \n",
       "35            1994  \n",
       "36            2000  \n",
       "37            1998  \n",
       "38            2006  \n",
       "39            1995  \n",
       "40            2006  \n",
       "41            2014  \n",
       "42            1942  \n",
       "43            1988  \n",
       "44            1962  \n",
       "45            2011  \n",
       "46            1936  \n",
       "47            1968  \n",
       "48            1954  \n",
       "49            1988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2. IMDB’s Top rated 100 movies’ data\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "html = urlopen('http://www.imdb.com/chart/top')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "movies = bs.select('td.titleColumn')\n",
    "ratings = [b.attrs.get('data-value') for b in bs.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "imdb = []\n",
    "\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 50):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    data = [movie_title,\n",
    "            ratings[index],\n",
    "            year\n",
    "            ]\n",
    "    imdb.append(data)\n",
    "    \n",
    "df = pd.DataFrame(imdb, columns=['Name', 'Rating', 'Year of Release'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    " \n",
    "# All dataframes hereafter reflect these changes.\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd663ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>8.548954920198527</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.410820726277477</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.396159917436936</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>8.39453385766035</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.388181177912017</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>777 Charlie</td>\n",
       "      <td>8.38680372244653</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.361056300102147</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.359461212831503</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.352917823553389</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.351368401980334</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>8.350263213699739</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#Home</td>\n",
       "      <td>8.325899852011746</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>8.315712882414575</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>8.313071158247938</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kumbalangi Nights</td>\n",
       "      <td>8.308853147051646</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.301189717609548</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.30066623487298</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>8.292205073926786</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>8.28013523850772</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kaithi</td>\n",
       "      <td>8.265615617009313</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>8.259673243360416</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>8.253760967834186</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maya Bazaar</td>\n",
       "      <td>8.24919191705495</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Natsamrat</td>\n",
       "      <td>8.236946614240916</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>8.23312648465733</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Asuran</td>\n",
       "      <td>8.232648146536661</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sita Ramam</td>\n",
       "      <td>8.231151884643893</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thevar Magan</td>\n",
       "      <td>8.227237107871641</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Visaaranai</td>\n",
       "      <td>8.219744182532732</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sarpatta Parambarai</td>\n",
       "      <td>8.213159367702012</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thalapathi</td>\n",
       "      <td>8.20755567142455</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.194949874652409</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nadodikkattu</td>\n",
       "      <td>8.188700313229246</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.176823403905624</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Jaane Bhi Do Yaaro</td>\n",
       "      <td>8.176339629855983</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>8.174754622192843</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sardar Udham</td>\n",
       "      <td>8.169408050183527</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Aparajito</td>\n",
       "      <td>8.166709005386922</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Vada Chennai</td>\n",
       "      <td>8.165809773932597</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>8.163711910260542</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>8.14949088657777</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ratsasan</td>\n",
       "      <td>8.147030927341499</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Chupke Chupke</td>\n",
       "      <td>8.137395030387818</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>8.133988518773426</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Peranbu</td>\n",
       "      <td>8.132342472084796</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.131434235550815</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mahanati</td>\n",
       "      <td>8.129359323519447</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>8.129092002410957</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Satya</td>\n",
       "      <td>8.126656063732097</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Premam</td>\n",
       "      <td>8.126204588694405</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name             Rating Year of Release\n",
       "0   Ramayana: The Legend of Prince Rama  8.548954920198527            1993\n",
       "1            Rocketry: The Nambi Effect  8.410820726277477            2022\n",
       "2                               Nayakan  8.396159917436936            1987\n",
       "3                              Gol Maal   8.39453385766035            1979\n",
       "4                            Anbe Sivam  8.388181177912017            2003\n",
       "5                           777 Charlie   8.38680372244653            2022\n",
       "6                              Jai Bhim  8.361056300102147            2021\n",
       "7                     Pariyerum Perumal  8.359461212831503            2018\n",
       "8                              3 Idiots  8.352917823553389            2009\n",
       "9                           Apur Sansar  8.351368401980334            1959\n",
       "10                     Manichitrathazhu  8.350263213699739            1993\n",
       "11                                #Home  8.325899852011746            2021\n",
       "12                      Soorarai Pottru  8.315712882414575            2020\n",
       "13                         Black Friday  8.313071158247938            2004\n",
       "14                    Kumbalangi Nights  8.308853147051646            2019\n",
       "15                    C/o Kancharapalem  8.301189717609548            2018\n",
       "16                     Taare Zameen Par   8.30066623487298            2007\n",
       "17                             Kireedam  8.292205073926786            1989\n",
       "18                               Dangal   8.28013523850772            2016\n",
       "19                               Kaithi  8.265615617009313            2019\n",
       "20                               Jersey  8.259673243360416            2019\n",
       "21                                   96  8.253760967834186            2018\n",
       "22                          Maya Bazaar   8.24919191705495            1957\n",
       "23                            Natsamrat  8.236946614240916            2016\n",
       "24                           Drishyam 2   8.23312648465733            2021\n",
       "25                               Asuran  8.232648146536661            2019\n",
       "26                           Sita Ramam  8.231151884643893            2022\n",
       "27                         Thevar Magan  8.227237107871641            1992\n",
       "28                           Visaaranai  8.219744182532732            2015\n",
       "29                  Sarpatta Parambarai  8.213159367702012            2021\n",
       "30                           Thalapathi   8.20755567142455            1991\n",
       "31                      Pather Panchali  8.194949874652409            1955\n",
       "32                         Nadodikkattu  8.188700313229246            1987\n",
       "33                             Drishyam  8.176823403905624            2013\n",
       "34                   Jaane Bhi Do Yaaro  8.176339629855983            1983\n",
       "35                         Thani Oruvan  8.174754622192843            2015\n",
       "36                         Sardar Udham  8.169408050183527            2021\n",
       "37                            Aparajito  8.166709005386922            1956\n",
       "38                         Vada Chennai  8.165809773932597            2018\n",
       "39                    Khosla Ka Ghosla!  8.163711910260542            2006\n",
       "40                              Anniyan   8.14949088657777            2005\n",
       "41                             Ratsasan  8.147030927341499            2018\n",
       "42                        Chupke Chupke  8.137395030387818            1975\n",
       "43                   Gangs of Wasseypur  8.133988518773426            2012\n",
       "44                              Peranbu  8.132342472084796            2018\n",
       "45                             Drishyam  8.131434235550815            2015\n",
       "46                             Mahanati  8.129359323519447            2018\n",
       "47                       Bangalore Days  8.129092002410957            2014\n",
       "48                                Satya  8.126656063732097            1998\n",
       "49                               Premam  8.126204588694405            2015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3. IMDB’s Top rated 100 Indian movies’ data\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "html = urlopen('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "movies = bs.select('td.titleColumn')\n",
    "ratings = [b.attrs.get('data-value') for b in bs.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "imdb = []\n",
    "\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 50):\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    data = [movie_title,\n",
    "            ratings[index],\n",
    "            year\n",
    "            ]\n",
    "    imdb.append(data)\n",
    "    \n",
    "df = pd.DataFrame(imdb, columns=['Name', 'Rating', 'Year of Release'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    " \n",
    "# All dataframes hereafter reflect these changes.\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40613a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                                         Term of Office  \n",
       "0                                       25 July, 2017 to 25 July, 2022   \n",
       "1                                       25 July, 2012 to 25 July, 2017   \n",
       "2                                       25 July, 2007 to 25 July, 2012   \n",
       "3                                       25 July, 2002 to 25 July, 2007   \n",
       "4                                       25 July, 1997 to 25 July, 2002   \n",
       "5                                       25 July, 1992 to 25 July, 1997   \n",
       "6                                       25 July, 1987 to 25 July, 1992   \n",
       "7                                       25 July, 1982 to 25 July, 1987   \n",
       "8                                       25 July, 1977 to 25 July, 1982   \n",
       "9                                  24 August, 1974 to 11 February, 1977  \n",
       "10  3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974  \n",
       "11                                          13 May, 1967 to 3 May, 1969  \n",
       "12                                         13 May, 1962 to 13 May, 1967  \n",
       "13                                     26 January, 1950 to 13 May, 1962  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4. List of respected former presidents of India\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "presidents = bs.find_all(\"div\", {\"class\": \"presidentListing\"})\n",
    "\n",
    "presidentsList = []\n",
    "\n",
    "for index in range(0, len(presidents)):\n",
    "    presidents_string = presidents[index].get_text()\n",
    "    president = presidents_string.split('\\n')[1]\n",
    "    term = presidents_string.split('\\n')[2].split(\": \")[1]\n",
    "    data = [president, term]\n",
    "    presidentsList.append(data)\n",
    "\n",
    "df = pd.DataFrame(presidentsList, columns=[\"Name\",\"Term of Office\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ffe94dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>44</td>\n",
       "      <td>5,010</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>29</td>\n",
       "      <td>3,229</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>3,656</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>27</td>\n",
       "      <td>2,775</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>33</td>\n",
       "      <td>3,129</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>34</td>\n",
       "      <td>2,976</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Matches Points Rating\n",
       "0         India      44  5,010    114\n",
       "1     Australia      32  3,572    112\n",
       "2   New Zealand      29  3,229    111\n",
       "3       England      33  3,656    111\n",
       "4      Pakistan      25  2,649    106\n",
       "5  South Africa      27  2,775    103\n",
       "6    Bangladesh      33  3,129     95\n",
       "7     Sri Lanka      34  2,976     88\n",
       "8   Afghanistan      20  1,419     71\n",
       "9   West Indies      41  2,902     71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5. a) Top 10 ODI Teams\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "firstTeamName = bs.select(\"td.rankings-block__banner--team-name span.u-hide-phablet\")[0];\n",
    "firstTeamMatches = bs.select(\"td.rankings-block__banner--matches\")[0];\n",
    "firstTeamPoints = bs.select(\"td.rankings-block__banner--points\")[0];\n",
    "firstTeamRating = bs.select(\"td.rankings-block__banner--rating\")[0];\n",
    "firstTeam = [firstTeamName.get_text(), firstTeamMatches.get_text(), firstTeamPoints.get_text(), firstTeamRating.get_text().strip()];\n",
    "\n",
    "\n",
    "restTeams = bs.select(\"tr.table-body\");\n",
    "restTeamNames = bs.select(\"td.rankings-table__team span.u-hide-phablet\");\n",
    "restTeamMatchesPoints = bs.select(\"td.u-center-text\");\n",
    "restTeamRatings = bs.select(\"td.rating\");\n",
    "\n",
    "restTeamMatches = [];\n",
    "restTeamPoints = [];\n",
    "\n",
    "for index in range(0, len(restTeamMatchesPoints)):\n",
    "    if (index%2 == 0):\n",
    "        restTeamMatches.append(restTeamMatchesPoints[index].get_text());\n",
    "    else:\n",
    "        restTeamPoints.append(restTeamMatchesPoints[index].get_text());\n",
    "        \n",
    "\n",
    "teamList = []\n",
    "teamList.append(firstTeam);\n",
    "\n",
    "for index in range(0, 9):\n",
    "    name = restTeamNames[index].get_text();\n",
    "    matches = restTeamMatches[index];\n",
    "    points = restTeamPoints[index];\n",
    "    ratings = restTeamRatings[index].get_text();\n",
    "    restTeam = [name, matches, points, ratings];\n",
    "    teamList.append(restTeam);\n",
    "\n",
    "\n",
    "df = pd.DataFrame(teamList, columns=[\"Name\",\"Matches\", \"Points\", \"Rating\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc1f3dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Team Rating\n",
       "0             Babar Azam  PAK    887\n",
       "1  Rassie van der Dussen   SA    787\n",
       "2           David Warner  AUS    747\n",
       "3        Quinton de Kock   SA    743\n",
       "4            Imam-ul-Haq  PAK    740\n",
       "5           Shubman Gill  IND    734\n",
       "6            Virat Kohli  IND    727\n",
       "7            Steve Smith  AUS    719\n",
       "8           Rohit Sharma  IND    719\n",
       "9        Kane Williamson   NZ    700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5. b) Top 10 ODI Batsmen\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "firstPlayerName = bs.select(\"div.rankings-block__banner--name-large\")[0];\n",
    "firstPlayerTeam = bs.select(\"div.rankings-block__banner--nationality\")[0];\n",
    "firstPlayerRating = bs.select(\"div.rankings-block__banner--rating\")[0];\n",
    "\n",
    "firstPlayer = [firstPlayerName.get_text().strip(),firstPlayerTeam.get_text().strip(),firstPlayerRating.get_text().strip()]\n",
    "\n",
    "restPlayerName = bs.select(\"td.rankings-table__name\");\n",
    "restPlayerTeam = bs.select(\"td.rankings-table__team\");\n",
    "restPlayerRating = bs.select(\"td.rating\");\n",
    "\n",
    "playerList = []\n",
    "playerList.append(firstPlayer);\n",
    "\n",
    "\n",
    "for index in range(0,9):\n",
    "    name = restPlayerName[index].get_text().strip();\n",
    "    team = restPlayerTeam[index].get_text().strip();\n",
    "    rating = restPlayerRating[index].get_text().strip();\n",
    "    playerList.append([name,team,rating]);\n",
    "    \n",
    "df = pd.DataFrame(playerList, columns=[\"Name\",\"Team\", \"Rating\"])\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b56e6195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Team Rating\n",
       "0     Mohammed Siraj  IND    729\n",
       "1     Josh Hazlewood  AUS    727\n",
       "2        Trent Boult   NZ    708\n",
       "3     Mitchell Starc  AUS    665\n",
       "4        Rashid Khan  AFG    659\n",
       "5         Adam Zampa  AUS    655\n",
       "6    Shakib Al Hasan  BAN    652\n",
       "7     Shaheen Afridi  PAK    641\n",
       "8  Mustafizur Rahman  BAN    638\n",
       "9   Mujeeb Ur Rahman  AFG    637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5. c) Top 10 ODI Bowlers\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "firstPlayerName = bs.select(\"div.rankings-block__banner--name-large\")[0];\n",
    "firstPlayerTeam = bs.select(\"div.rankings-block__banner--nationality\")[0];\n",
    "firstPlayerRating = bs.select(\"div.rankings-block__banner--rating\")[0];\n",
    "\n",
    "firstPlayer = [firstPlayerName.get_text().strip(),firstPlayerTeam.get_text().strip(),firstPlayerRating.get_text().strip()]\n",
    "\n",
    "restPlayerName = bs.select(\"td.rankings-table__name\");\n",
    "restPlayerTeam = bs.select(\"td.rankings-table__team\");\n",
    "restPlayerRating = bs.select(\"td.rating\");\n",
    "\n",
    "playerList = []\n",
    "playerList.append(firstPlayer);\n",
    "\n",
    "\n",
    "for index in range(0,9):\n",
    "    name = restPlayerName[index].get_text().strip();\n",
    "    team = restPlayerTeam[index].get_text().strip();\n",
    "    rating = restPlayerRating[index].get_text().strip();\n",
    "    playerList.append([name,team,rating]);\n",
    "    \n",
    "df = pd.DataFrame(playerList, columns=[\"Name\",\"Team\", \"Rating\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06124396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Matches Points Rating\n",
       "0     Australia      21  3,603    172\n",
       "1       England      28  3,342    119\n",
       "2  South Africa      26  3,098    119\n",
       "3         India      27  2,820    104\n",
       "4   New Zealand      25  2,553    102\n",
       "5   West Indies      27  2,535     94\n",
       "6    Bangladesh      13    983     76\n",
       "7      Thailand       8    572     72\n",
       "8      Pakistan      27  1,678     62\n",
       "9     Sri Lanka       8    353     44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6. a) Top 10 ODI Teams - Women\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "firstTeamName = bs.select(\"td.rankings-block__banner--team-name span.u-hide-phablet\")[0];\n",
    "firstTeamMatches = bs.select(\"td.rankings-block__banner--matches\")[0];\n",
    "firstTeamPoints = bs.select(\"td.rankings-block__banner--points\")[0];\n",
    "firstTeamRating = bs.select(\"td.rankings-block__banner--rating\")[0];\n",
    "firstTeam = [firstTeamName.get_text(), firstTeamMatches.get_text(), firstTeamPoints.get_text(), firstTeamRating.get_text().strip()];\n",
    "\n",
    "\n",
    "restTeams = bs.select(\"tr.table-body\");\n",
    "restTeamNames = bs.select(\"td.rankings-table__team span.u-hide-phablet\");\n",
    "restTeamMatchesPoints = bs.select(\"td.u-center-text\");\n",
    "restTeamRatings = bs.select(\"td.rating\");\n",
    "\n",
    "restTeamMatches = [];\n",
    "restTeamPoints = [];\n",
    "\n",
    "for index in range(0, len(restTeamMatchesPoints)):\n",
    "    if (index%2 == 0):\n",
    "        restTeamMatches.append(restTeamMatchesPoints[index].get_text());\n",
    "    else:\n",
    "        restTeamPoints.append(restTeamMatchesPoints[index].get_text());\n",
    "        \n",
    "\n",
    "teamList = []\n",
    "teamList.append(firstTeam);\n",
    "\n",
    "for index in range(0, 9):\n",
    "    name = restTeamNames[index].get_text();\n",
    "    matches = restTeamMatches[index];\n",
    "    points = restTeamPoints[index];\n",
    "    ratings = restTeamRatings[index].get_text();\n",
    "    restTeam = [name, matches, points, ratings];\n",
    "    teamList.append(restTeam);\n",
    "\n",
    "\n",
    "df = pd.DataFrame(teamList, columns=[\"Name\",\"Matches\", \"Points\", \"Rating\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a895c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Team Rating\n",
       "0         Alyssa Healy  AUS    762\n",
       "1          Beth Mooney  AUS    754\n",
       "2      Laura Wolvaardt   SA    732\n",
       "3       Natalie Sciver  ENG    731\n",
       "4          Meg Lanning  AUS    717\n",
       "5     Harmanpreet Kaur  IND    716\n",
       "6      Smriti Mandhana  IND    714\n",
       "7       Rachael Haynes  AUS    680\n",
       "8  Chamari Athapaththu   SL    655\n",
       "9    Amy Satterthwaite   NZ    641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6. b) Top 10 ODI Batsmen - Women\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "firstPlayerName = bs.select(\"div.rankings-block__banner--name-large\")[0];\n",
    "firstPlayerTeam = bs.select(\"div.rankings-block__banner--nationality\")[0];\n",
    "firstPlayerRating = bs.select(\"div.rankings-block__banner--rating\")[0];\n",
    "\n",
    "firstPlayer = [firstPlayerName.get_text().strip(),firstPlayerTeam.get_text().strip(),firstPlayerRating.get_text().strip()]\n",
    "\n",
    "restPlayerName = bs.select(\"td.rankings-table__name\");\n",
    "restPlayerTeam = bs.select(\"td.rankings-table__team\");\n",
    "restPlayerRating = bs.select(\"td.rating\");\n",
    "\n",
    "playerList = []\n",
    "playerList.append(firstPlayer);\n",
    "\n",
    "\n",
    "for index in range(0,9):\n",
    "    name = restPlayerName[index].get_text().strip();\n",
    "    team = restPlayerTeam[index].get_text().strip();\n",
    "    rating = restPlayerRating[index].get_text().strip();\n",
    "    playerList.append([name,team,rating]);\n",
    "    \n",
    "df = pd.DataFrame(playerList, columns=[\"Name\",\"Team\", \"Rating\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad47afe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Team Rating\n",
       "0    Sophie Ecclestone  ENG    751\n",
       "1        Jess Jonassen  AUS    723\n",
       "2       Shabnim Ismail   SA    722\n",
       "3         Megan Schutt  AUS    704\n",
       "4       Jhulan Goswami  IND    698\n",
       "5      Hayley Matthews   WI    660\n",
       "6           Kate Cross  ENG    655\n",
       "7       Ayabonga Khaka   SA    634\n",
       "8  Rajeshwari Gayakwad  IND    617\n",
       "9       Marizanne Kapp   SA    598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6. c) Top 10 ODI Bowlers - Women\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "firstPlayerName = bs.select(\"div.rankings-block__banner--name-large\")[0];\n",
    "firstPlayerTeam = bs.select(\"div.rankings-block__banner--nationality\")[0];\n",
    "firstPlayerRating = bs.select(\"div.rankings-block__banner--rating\")[0];\n",
    "\n",
    "firstPlayer = [firstPlayerName.get_text().strip(),firstPlayerTeam.get_text().strip(),firstPlayerRating.get_text().strip()]\n",
    "\n",
    "restPlayerName = bs.select(\"td.rankings-table__name\");\n",
    "restPlayerTeam = bs.select(\"td.rankings-table__team\");\n",
    "restPlayerRating = bs.select(\"td.rating\");\n",
    "\n",
    "playerList = []\n",
    "playerList.append(firstPlayer);\n",
    "\n",
    "\n",
    "for index in range(0,9):\n",
    "    name = restPlayerName[index].get_text().strip();\n",
    "    team = restPlayerTeam[index].get_text().strip();\n",
    "    rating = restPlayerRating[index].get_text().strip();\n",
    "    playerList.append([name,team,rating]);\n",
    "    \n",
    "df = pd.DataFrame(playerList, columns=[\"Name\",\"Team\", \"Rating\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc7579aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim Chanos says he’s still betting against Coinbase</td>\n",
       "      <td>8 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/jim-chanos-says-hes-still-betting-against-coinbase-even-with-a-70percent-rally-this-year.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West Virginia aims to toss lawsuit seeking to overturn abortion pill restrictions</td>\n",
       "      <td>10 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/west-virginia-seeks-to-dismiss-lawsuit-over-abortion-pill-access.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much money you'd have if you invested $1,000 in Walmart 10 years ago</td>\n",
       "      <td>28 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/walmart-how-much-money-youd-have-if-you-invested-1000-dollars-a-decade-ago.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FedEx pilot union inches closer to strike with authorization vote approval</td>\n",
       "      <td>32 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/fedex-pilot-leaders-approve-strike-authorization-vote.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Republicans seek records on SEC's climate proposal as part of push against ESG</td>\n",
       "      <td>38 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/republicans-seek-records-on-sec-climate-disclosure-proposal-.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trump daughter, son-in-law Kushner subpoenaed in Jan. 6 criminal probe: report</td>\n",
       "      <td>42 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/trump-daughter-ivanka-son-in-law-jared-kushner-subpoenaed-in-jan-6-criminal-probe-report.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lucid's revenue falls short as it guides to higher EV production in 2023</td>\n",
       "      <td>42 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/lucid-lcid-earnings-q4-2022.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UN urged to do more for sailors, ships trapped in Ukraine since start of war</td>\n",
       "      <td>44 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/un-urged-to-help-sailors-ships-trapped-in-ukraine-since-war-started.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biden Interior proposes first offshore wind lease sale in Gulf of Mexico</td>\n",
       "      <td>54 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/biden-proposes-first-offshore-wind-lease-sale-in-gulf-of-mexico.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>China provinces and Florida rank among the world's most climate-vulnerable areas</td>\n",
       "      <td>56 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/china-provinces-florida-among-worlds-most-climate-vulnerable-areas.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Why we need a nationwide electric grid in the U.S., but don't have one</td>\n",
       "      <td>59 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/why-we-need-nationwide-electric-grid-in-the-us-but-dont-have-one.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SCOTUS considers whether Twitter can be held liable for failing to remove terrorists</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/supreme-court-hears-twitter-v-taamneh-case-about-terrorist-content.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This stock has 20% upside and could get a boost in tax season, Wells Fargo says</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/this-stock-has-20percent-upside-and-could-get-a-boost-in-tax-season-wells-fargo-says.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Falling behind on federal student loans can lead to other big financial problems</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/falling-behind-on-student-loans-can-lead-to-other-financial-problems.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Why Josh Brown likes this high-beta cybersecurity stock</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/why-josh-brown-likes-this-high-beta-cybersecurity-stock.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gen Z college students say this is the most important thing to them in a new job</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/gen-z-college-students-on-most-important-thing-to-them-in-a-new-job.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How to invest in 'extremely disruptive' AI tech</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/how-to-invest-in-artificial-intelligence-etfs.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How to boost your portfolio income when companies cut dividends</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/how-to-boost-your-portfolio-income-when-companies-cut-dividends.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Supreme Court rules bankruptcy filers can't avoid debt due to another's fraud</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/supreme-court-rules-bankruptcy-no-shield-to-fraud-debt.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S&amp;P 500 earnings beats hit a 15-year low. More cost cuts are coming</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/sp-500-earnings-beats-hit-15-year-low-more-cost-cuts-are-coming.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Musk meets with California Gov. Newsom at Tesla's new engineering HQ</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/elon-musk-meets-with-california-gov-newsom-at-teslas-engineering-hq.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>These dividend stocks offer growth, quality during a tumultuous market, UBS says</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/ubs-likes-these-high-quality-dividend-stocks-to-weather-a-downturn.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Quiet quitting is 'not going anywhere'—and could get worse this year</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/lackluster-raises-mass-layoffs-could-lead-to-new-quiet-quitting-wave.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CDC advisors recommend mpox vaccine for at-risk adults in future outbreaks</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/mpox-cdc-advisors-recommend-vaccine-for-at-risk-adults-in-future-outbreaks.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Off-price retailer TJX's quarterly results show strong demand</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/off-price-retailer-tjxs-quarterly-results-show-strong-demand.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Flu shot 68% effective against hospitalization in kids, less protective for seniors</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/flu-vaccine-cdc-releases-effectiveness-data-for-children-and-seniors.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Amazon, Wells Fargo, Microsoft, Nvidia are in the news. Here's our take</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/amazon-wells-fargo-microsoft-nvidia-are-in-the-headlines-our-club-take.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fed minutes show members resolved to keep fighting inflation with rate hikes</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/fed-minutes-february-2023-minutes-show-fed-members-resolved-to-keep-fighting-inflation.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stay away: These stocks are expensive and vulnerable, Wolfe Research says</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/stay-away-these-stocks-are-expensive-and-vulnerable-one-firm-says.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Luminar and Mercedes-Benz expand lidar partnership for driver-assist system</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/22/luminar-mercedes-benz-lidar-partnership.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Headline  \\\n",
       "0                                   Jim Chanos says he’s still betting against Coinbase    \n",
       "1      West Virginia aims to toss lawsuit seeking to overturn abortion pill restrictions   \n",
       "2               How much money you'd have if you invested $1,000 in Walmart 10 years ago   \n",
       "3             FedEx pilot union inches closer to strike with authorization vote approval   \n",
       "4        Republicans seek records on SEC's climate proposal as part of push against ESG    \n",
       "5         Trump daughter, son-in-law Kushner subpoenaed in Jan. 6 criminal probe: report   \n",
       "6               Lucid's revenue falls short as it guides to higher EV production in 2023   \n",
       "7           UN urged to do more for sailors, ships trapped in Ukraine since start of war   \n",
       "8               Biden Interior proposes first offshore wind lease sale in Gulf of Mexico   \n",
       "9       China provinces and Florida rank among the world's most climate-vulnerable areas   \n",
       "10                Why we need a nationwide electric grid in the U.S., but don't have one   \n",
       "11  SCOTUS considers whether Twitter can be held liable for failing to remove terrorists   \n",
       "12       This stock has 20% upside and could get a boost in tax season, Wells Fargo says   \n",
       "13      Falling behind on federal student loans can lead to other big financial problems   \n",
       "14                               Why Josh Brown likes this high-beta cybersecurity stock   \n",
       "15      Gen Z college students say this is the most important thing to them in a new job   \n",
       "16                                       How to invest in 'extremely disruptive' AI tech   \n",
       "17                       How to boost your portfolio income when companies cut dividends   \n",
       "18         Supreme Court rules bankruptcy filers can't avoid debt due to another's fraud   \n",
       "19                   S&P 500 earnings beats hit a 15-year low. More cost cuts are coming   \n",
       "20                  Musk meets with California Gov. Newsom at Tesla's new engineering HQ   \n",
       "21      These dividend stocks offer growth, quality during a tumultuous market, UBS says   \n",
       "22                  Quiet quitting is 'not going anywhere'—and could get worse this year   \n",
       "23            CDC advisors recommend mpox vaccine for at-risk adults in future outbreaks   \n",
       "24                         Off-price retailer TJX's quarterly results show strong demand   \n",
       "25   Flu shot 68% effective against hospitalization in kids, less protective for seniors   \n",
       "26               Amazon, Wells Fargo, Microsoft, Nvidia are in the news. Here's our take   \n",
       "27          Fed minutes show members resolved to keep fighting inflation with rate hikes   \n",
       "28             Stay away: These stocks are expensive and vulnerable, Wolfe Research says   \n",
       "29           Luminar and Mercedes-Benz expand lidar partnership for driver-assist system   \n",
       "\n",
       "           Time  \\\n",
       "0     8 Min Ago   \n",
       "1    10 Min Ago   \n",
       "2    28 Min Ago   \n",
       "3    32 Min Ago   \n",
       "4    38 Min Ago   \n",
       "5    42 Min Ago   \n",
       "6    42 Min Ago   \n",
       "7    44 Min Ago   \n",
       "8    54 Min Ago   \n",
       "9    56 Min Ago   \n",
       "10   59 Min Ago   \n",
       "11   1 Hour Ago   \n",
       "12   1 Hour Ago   \n",
       "13   1 Hour Ago   \n",
       "14   1 Hour Ago   \n",
       "15  2 Hours Ago   \n",
       "16  2 Hours Ago   \n",
       "17  2 Hours Ago   \n",
       "18  2 Hours Ago   \n",
       "19  2 Hours Ago   \n",
       "20  2 Hours Ago   \n",
       "21  2 Hours Ago   \n",
       "22  2 Hours Ago   \n",
       "23  2 Hours Ago   \n",
       "24  2 Hours Ago   \n",
       "25  3 Hours Ago   \n",
       "26  3 Hours Ago   \n",
       "27  3 Hours Ago   \n",
       "28  3 Hours Ago   \n",
       "29  3 Hours Ago   \n",
       "\n",
       "                                                                                                                        News Link  \n",
       "0   https://www.cnbc.com/2023/02/22/jim-chanos-says-hes-still-betting-against-coinbase-even-with-a-70percent-rally-this-year.html  \n",
       "1                           https://www.cnbc.com/2023/02/22/west-virginia-seeks-to-dismiss-lawsuit-over-abortion-pill-access.html  \n",
       "2                 https://www.cnbc.com/2023/02/22/walmart-how-much-money-youd-have-if-you-invested-1000-dollars-a-decade-ago.html  \n",
       "3                                      https://www.cnbc.com/2023/02/22/fedex-pilot-leaders-approve-strike-authorization-vote.html  \n",
       "4                               https://www.cnbc.com/2023/02/22/republicans-seek-records-on-sec-climate-disclosure-proposal-.html  \n",
       "5   https://www.cnbc.com/2023/02/22/trump-daughter-ivanka-son-in-law-jared-kushner-subpoenaed-in-jan-6-criminal-probe-report.html  \n",
       "6                                                                https://www.cnbc.com/2023/02/22/lucid-lcid-earnings-q4-2022.html  \n",
       "7                        https://www.cnbc.com/2023/02/22/un-urged-to-help-sailors-ships-trapped-in-ukraine-since-war-started.html  \n",
       "8                            https://www.cnbc.com/2023/02/22/biden-proposes-first-offshore-wind-lease-sale-in-gulf-of-mexico.html  \n",
       "9                         https://www.cnbc.com/2023/02/22/china-provinces-florida-among-worlds-most-climate-vulnerable-areas.html  \n",
       "10                          https://www.cnbc.com/2023/02/22/why-we-need-nationwide-electric-grid-in-the-us-but-dont-have-one.html  \n",
       "11                        https://www.cnbc.com/2023/02/22/supreme-court-hears-twitter-v-taamneh-case-about-terrorist-content.html  \n",
       "12      https://www.cnbc.com/2023/02/22/this-stock-has-20percent-upside-and-could-get-a-boost-in-tax-season-wells-fargo-says.html  \n",
       "13                      https://www.cnbc.com/2023/02/22/falling-behind-on-student-loans-can-lead-to-other-financial-problems.html  \n",
       "14                                   https://www.cnbc.com/2023/02/22/why-josh-brown-likes-this-high-beta-cybersecurity-stock.html  \n",
       "15                       https://www.cnbc.com/2023/02/22/gen-z-college-students-on-most-important-thing-to-them-in-a-new-job.html  \n",
       "16                                             https://www.cnbc.com/2023/02/22/how-to-invest-in-artificial-intelligence-etfs.html  \n",
       "17                           https://www.cnbc.com/2023/02/22/how-to-boost-your-portfolio-income-when-companies-cut-dividends.html  \n",
       "18                                    https://www.cnbc.com/2023/02/22/supreme-court-rules-bankruptcy-no-shield-to-fraud-debt.html  \n",
       "19                           https://www.cnbc.com/2023/02/22/sp-500-earnings-beats-hit-15-year-low-more-cost-cuts-are-coming.html  \n",
       "20                       https://www.cnbc.com/2023/02/22/elon-musk-meets-with-california-gov-newsom-at-teslas-engineering-hq.html  \n",
       "21                        https://www.cnbc.com/2023/02/22/ubs-likes-these-high-quality-dividend-stocks-to-weather-a-downturn.html  \n",
       "22                      https://www.cnbc.com/2023/02/22/lackluster-raises-mass-layoffs-could-lead-to-new-quiet-quitting-wave.html  \n",
       "23                https://www.cnbc.com/2023/02/22/mpox-cdc-advisors-recommend-vaccine-for-at-risk-adults-in-future-outbreaks.html  \n",
       "24                              https://www.cnbc.com/2023/02/22/off-price-retailer-tjxs-quarterly-results-show-strong-demand.html  \n",
       "25                      https://www.cnbc.com/2023/02/22/flu-vaccine-cdc-releases-effectiveness-data-for-children-and-seniors.html  \n",
       "26                    https://www.cnbc.com/2023/02/22/amazon-wells-fargo-microsoft-nvidia-are-in-the-headlines-our-club-take.html  \n",
       "27    https://www.cnbc.com/2023/02/22/fed-minutes-february-2023-minutes-show-fed-members-resolved-to-keep-fighting-inflation.html  \n",
       "28                         https://www.cnbc.com/2023/02/22/stay-away-these-stocks-are-expensive-and-vulnerable-one-firm-says.html  \n",
       "29                                                   https://www.cnbc.com/2023/02/22/luminar-mercedes-benz-lidar-partnership.html  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#7. News details from https://www.cnbc.com/world/?region=world\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.cnbc.com/world/?region=world')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "headLinesTimestampList = bs.select(\"time.LatestNews-timestamp\");\n",
    "headLinesTitleList = bs.select(\"a.LatestNews-headline\");\n",
    "headLinesLinkList = [b.attrs.get('href') for b in bs.select('a.LatestNews-headline')]\n",
    "\n",
    "\n",
    "latest_news = []\n",
    "\n",
    "for index in range(0,len(headLinesTitleList)):\n",
    "    headline = headLinesTitleList[index].get_text();\n",
    "    time = headLinesTimestampList[index].get_text();\n",
    "    news_link = headLinesLinkList[index];\n",
    "    latest_news.append([headline, time, news_link]);\n",
    "    \n",
    "df = pd.DataFrame(latest_news, columns=[\"Headline\",\"Time\", \"News Link\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "####8. Most downloaded article https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "PeperTitleList = bs.select(\"a.nrDZj\");\n",
    "AuthorList = bs.select(\"span.pgLAT\");\n",
    "PublishedDateList = bs.select(\"span.bKddwo\");\n",
    "PaperLinkList = [b.attrs.get('href') for b in bs.select('a.nrDZj')]\n",
    "\n",
    "\n",
    "latest_papers = []\n",
    "\n",
    "for index in range(0,len(PeperTitleList)):\n",
    "    title = PeperTitleList[index].get_text().strip();\n",
    "    author = AuthorList[index].get_text();\n",
    "    publishedon = PublishedDateList[index].get_text();\n",
    "    paper_link = PaperLinkList[index];\n",
    "    latest_papers.append([title, author, publishedon, paper_link]);\n",
    "    \n",
    "df = pd.DataFrame(latest_papers, columns=[\"Paper Title\",\"Authors\", \"Published Date\", \"Paper URL\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfdfbfff",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m bs \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m PeperTitleList \u001b[38;5;241m=\u001b[39m bs\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma.nrDZj\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:1349\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1347\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1350\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)>"
     ]
    }
   ],
   "source": [
    "#8. Most downloaded article https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "html = urlopen('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "PeperTitleList = bs.select(\"a.nrDZj\");\n",
    "AuthorList = bs.select(\"span.pgLAT\");\n",
    "PublishedDateList = bs.select(\"span.bKddwo\");\n",
    "PaperLinkList = [b.attrs.get('href') for b in bs.select('a.nrDZj')]\n",
    "\n",
    "\n",
    "latest_papers = []\n",
    "\n",
    "for index in range(0,len(PeperTitleList)):\n",
    "    title = PeperTitleList[index].get_text().strip();\n",
    "    author = AuthorList[index].get_text();\n",
    "    publishedon = PublishedDateList[index].get_text();\n",
    "    paper_link = PaperLinkList[index];\n",
    "    latest_papers.append([title, author, publishedon, paper_link]);\n",
    "    \n",
    "df = pd.DataFrame(latest_papers, columns=[\"Paper Title\",\"Authors\", \"Published Date\", \"Paper URL\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eda86898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, East Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>Continental</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name       Cuisine  \\\n",
       "0                   Castle Barbeque       Chinese   \n",
       "1                   Jungle Jamboree  North Indian   \n",
       "2                        Cafe Knosh  North Indian   \n",
       "3                   Castle Barbeque         Asian   \n",
       "4              The Barbeque Company       Italian   \n",
       "5                       India Grill       Italian   \n",
       "6                    Delhi Barbeque   Continental   \n",
       "7  The Monarch - Bar Be Que Village       Chinese   \n",
       "8                 Indian Grill Room  North Indian   \n",
       "\n",
       "                                                   Location Ratings  \\\n",
       "0                            Connaught Place, Central Delhi     4.1   \n",
       "1                    3CS Mall,Lajpat Nagar - 3, South Delhi     4.3   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, East Delhi     3.9   \n",
       "3                    Pacific Mall,Tagore Garden, West Delhi     4.3   \n",
       "4                        Gardens Galleria,Sector 38A, Noida     4.3   \n",
       "5                      Hilton Garden Inn,Saket, South Delhi     4.3   \n",
       "6            Taurus Sarovar Portico,Mahipalpur, South Delhi     3.9   \n",
       "7         Indirapuram Habitat Centre,Indirapuram, Ghaziabad     4.3   \n",
       "8          Suncity Business Tower,Golf Course Road, Gurgaon     3.9   \n",
       "\n",
       "                                                                                                             Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium  \n",
       "1  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium  \n",
       "2    https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium  \n",
       "3  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium  \n",
       "4  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium  \n",
       "5   https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium  \n",
       "6  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium  \n",
       "7  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium  \n",
       "8    https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#9. Details from dineout.co.in\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request('https://www.dineout.co.in/delhi-restaurants/buffet-special',headers=hdr)\n",
    "html = urlopen(req)\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "NameList = bs.select(\"a.restnt-name\");\n",
    "CuisineList = bs.select(\"span.double-line-ellipsis a\");\n",
    "Location = bs.select(\"div.restnt-loc\");\n",
    "Ratings = bs.select(\"div.restnt-rating\");\n",
    "ImgURL = [b.attrs.get('data-src') for b in bs.select('img.no-img')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "restaurant_list = []\n",
    "\n",
    "\n",
    "for index in range(0,len(NameList)):\n",
    "    name = NameList[index].get_text().strip();\n",
    "    cuisine = CuisineList[index].get_text().strip();\n",
    "    location = Location[index].get_text().strip();\n",
    "    ratings = Ratings[index].get_text();\n",
    "    imgURL = ImgURL[index];\n",
    "    restaurant_list.append([name, cuisine, location, ratings, imgURL]);\n",
    "    \n",
    "df = pd.DataFrame(restaurant_list, columns=[\"Restaurant Name\",\"Cuisine\", \"Location\", \"Ratings\",\"Image URL\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883db8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
